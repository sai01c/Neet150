## Time Complexity

- Time complexity is defined as number of basic operations performed as a function of input size. 
- It is independent of computer, language etc. 
- It is designed to be universal so we can compare algorithm's. 

### Recursive algorithm

- Runtime of a recursive algorithm with branches is O(branches ^ depth).
- Implict stack grows in the memory. So, you need to account for recursive calls, it won't be constant memory. 

### If Else condition

- In case of condition statements, we pick the complexity that is highest because we want to look for the worst case TC. 

### Love Babbar- Time and Space Complexity Analysis:

- Time taken for the function to run as a function of input.
- If time for our algo is very high, we'll get TLE- Time Limit Exceed error.
- How to avoid TLE: Present machine's can solve 10^8 operations per second.

### Cracking the coding interview book - 

- Amortized time complexity - Time complexity is very high occasionally but it is less for most of the operations. 
- Example: Dynamic Arraylist - Inserting element is O(1) if the array has space. If the array is full then it doubles the size and copies prev elements. 
- So, inserting will be O(n) when array is full. 

## General Rules for TC:

- For condition statements, there's no fixed structure, it varies depending upon condition.
- Look at the upper bound in for/while loops. If i < n => Tc is O(n) Else if i * i => Tc is sqrt(n).
- Runtime of a recursive algorithm with branches is O(branches ^ depth).
- If i < a then Tc is O(a). 
- If i is added or subtracted then Tc will remain O(n). But, if i is either multiplied or divided then Tc is O(log n). 

## Space Complexity:

- Memory taken by algorithm to run.
- Variables constant memory O(1)
- Arrays O(n)
- Space complexity is independent of loops.
